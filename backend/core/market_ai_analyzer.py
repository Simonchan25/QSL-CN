"""
QSL-AI å¸‚åœºåˆ†ææ¨¡å—
æä¾›5ç»´åº¦æ™ºèƒ½å¸‚åœºåˆ†æï¼š
1. å¸‚åœºæƒ…ç»ªè§£è¯» - æ¶¨è·Œå®¶æ•°ã€èµ„é‡‘æµå‘ã€æ¿å—åˆ†å¸ƒ
2. èµ„é‡‘æµå‘ä¸èèµ„åˆ†æ - ä¸»åŠ›èµ„é‡‘ã€åŒ—å‘èµ„é‡‘ã€SHIBOR
3. æŒ‡æ•°ä¸æ¿å—ç»“æ„åˆ†æ - å¤§ç›˜æŒ‡æ•°ã€è¡Œä¸šè½®åŠ¨
4. å®è§‚ä¸å¤–éƒ¨ç¯å¢ƒ - æ±‡ç‡ã€å¤§å®—å•†å“ã€æµ·å¤–å¸‚åœº
5. å…¬å‘Šä¸æ–°é—»æ‘˜è¦ - æ”¿ç­–è§£è¯»ã€é‡è¦å…¬å‘Šå½±å“
"""

from __future__ import annotations
import datetime as dt
from typing import Dict, Any, List, Optional
import json
import logging
import os

try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥
    from ..nlp.ollama_client import summarize_hotspot, OLLAMA_MODEL, OLLAMA_URL
except ImportError:
    try:
        # å°è¯•ç»å¯¹å¯¼å…¥
        import sys
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
        from nlp.ollama_client import summarize_hotspot, OLLAMA_MODEL, OLLAMA_URL
    except ImportError:
        # é»˜è®¤å€¼
        OLLAMA_MODEL = "qwen3:8b"
        OLLAMA_URL = "http://localhost:11434"
        summarize_hotspot = None

logger = logging.getLogger(__name__)


class MarketAIAnalyzer:
    """QSL-AI å¸‚åœºåˆ†æå™¨"""
    
    def __init__(self):
        self.analysis_dimensions = {
            "sentiment": "å¸‚åœºæƒ…ç»ªè§£è¯»",
            "capital": "èµ„é‡‘æµå‘åˆ†æ", 
            "structure": "æŒ‡æ•°æ¿å—ç»“æ„",
            "macro": "å®è§‚å¤–éƒ¨ç¯å¢ƒ",
            "news": "å…¬å‘Šæ–°é—»è§£è¯»",
            "hotspots": "å®æ—¶çƒ­ç‚¹è¿½è¸ª",
            "alerts": "æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ"
        }
        # æƒ…ç»ªæŒ‡æ ‡æƒé‡é…ç½®
        self.sentiment_weights = {
            "up_down_ratio": 0.30,
            "limit_boards": 0.25,
            "north_funds": 0.20,
            "volume_energy": 0.15,
            "vix_equivalent": 0.10
        }
    
    def analyze_comprehensive_market(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç»¼åˆåˆ†æå¸‚åœºæ•°æ®ï¼Œç”Ÿæˆ5ç»´åº¦æ™ºèƒ½åˆ†æ
        
        Args:
            market_data: æ¥è‡ªfetch_market_overview()çš„å®Œæ•´å¸‚åœºæ•°æ®
            
        Returns:
            åŒ…å«5ä¸ªç»´åº¦åˆ†æç»“æœçš„å­—å…¸
        """
        try:
            analysis = {}
            
            # 1. å¸‚åœºæƒ…ç»ªè§£è¯»
            analysis["sentiment"] = self._analyze_market_sentiment(market_data)
            
            # 2. èµ„é‡‘æµå‘ä¸èèµ„åˆ†æ  
            analysis["capital"] = self._analyze_capital_flow(market_data)
            
            # 3. æŒ‡æ•°ä¸æ¿å—ç»“æ„åˆ†æ
            analysis["structure"] = self._analyze_index_structure(market_data)
            
            # 4. å®è§‚ä¸å¤–éƒ¨ç¯å¢ƒ
            analysis["macro"] = self._analyze_macro_environment(market_data)
            
            # 5. å…¬å‘Šä¸æ–°é—»æ‘˜è¦
            analysis["news"] = self._analyze_news_announcements(market_data)
            
            # 6. å®æ—¶çƒ­ç‚¹è¿½è¸ª
            analysis["hotspots"] = self._analyze_market_hotspots(market_data)
            
            # 7. æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ
            analysis["alerts"] = self._generate_market_alerts(analysis)
            
            # 8. ææ…Œè´ªå©ªæŒ‡æ•°
            analysis["fear_greed_index"] = self._calculate_fear_greed_index(analysis)
            
            # 9. LLMæ™ºèƒ½è§£è¯»
            analysis["intelligent_narrative"] = self._generate_intelligent_narrative(analysis)
            
            # ç»¼åˆè¯„ä¼°å’Œæ“ä½œå»ºè®®
            analysis["summary"] = self._generate_overall_assessment(market_data, analysis)
            
            # æ·»åŠ ç”Ÿæˆæ—¶é—´æˆ³
            analysis["generated_at"] = dt.datetime.now().isoformat()
            analysis["data_timestamp"] = market_data.get("timestamp")
            
            return analysis
            
        except Exception as e:
            logger.error(f"ç»¼åˆå¸‚åœºåˆ†æå¤±è´¥: {e}")
            return self._get_fallback_analysis()
    
    def _analyze_market_sentiment(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¸‚åœºæƒ…ç»ª - åŸºäºæ¶¨è·Œå®¶æ•°ã€æ¶¨åœæ¿ã€å¤§ä¸­å°ç›˜è¡¨ç°"""
        try:
            sentiment_data = {}
            breadth = market_data.get("market_breadth", {})
            indices = market_data.get("indices", [])
            
            # è®¡ç®—ä¸»è¦æŒ‡æ•°å¹³å‡æ¶¨è·Œå¹…
            valid_indices = [idx for idx in indices if idx.get("pct_chg") is not None]
            avg_change = sum(idx["pct_chg"] for idx in valid_indices) / len(valid_indices) if valid_indices else 0
            
            # æ¶¨è·Œå®¶æ•°åˆ†æ
            up_count = breadth.get("up_count", 0)
            down_count = breadth.get("down_count", 0)
            total_count = breadth.get("total_count", 1)
            up_ratio = (up_count / total_count * 100) if total_count > 0 else 0
            
            sentiment_data["up_down_ratio"] = {
                "up_count": up_count,
                "down_count": down_count,
                "up_ratio": round(up_ratio, 1),
                "analysis": self._interpret_up_down_ratio(up_ratio)
            }
            
            # æ¶¨åœè·Œåœåˆ†æ
            limit_up = breadth.get("limit_up", 0) 
            limit_down = breadth.get("limit_down", 0)
            sentiment_data["limit_analysis"] = {
                "limit_up": limit_up,
                "limit_down": limit_down,
                "analysis": self._interpret_limit_boards(limit_up, limit_down)
            }
            
            # å¤§ä¸­å°ç›˜è¡¨ç°åˆ†æ
            large_cap_up = breadth.get("large_cap_up", 0)
            mid_cap_up = breadth.get("mid_cap_up", 0) 
            small_cap_up = breadth.get("small_cap_up", 0)
            sentiment_data["market_cap_analysis"] = {
                "large_cap_up": large_cap_up,
                "mid_cap_up": mid_cap_up,
                "small_cap_up": small_cap_up,
                "analysis": self._interpret_market_cap_performance(large_cap_up, mid_cap_up, small_cap_up)
            }
            
            # æ•´ä½“æƒ…ç»ªè¯„çº§ (1-10åˆ†)
            emotion_score = self._calculate_emotion_score(up_ratio, avg_change, limit_up, limit_down)
            sentiment_data["emotion_score"] = emotion_score
            sentiment_data["overall_sentiment"] = self._get_sentiment_description(emotion_score)
            
            return sentiment_data
            
        except Exception as e:
            logger.error(f"å¸‚åœºæƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return {"error": "å¸‚åœºæƒ…ç»ªæ•°æ®æš‚æ—¶æ— æ³•åˆ†æ"}
    
    def _analyze_capital_flow(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æèµ„é‡‘æµå‘ - åŒ—å‘èµ„é‡‘ã€èèµ„èåˆ¸ã€ä¸»åŠ›èµ„é‡‘ã€SHIBOR"""
        try:
            capital_data = {}
            flow_data = market_data.get("capital_flow", {})
            shibor_data = market_data.get("shibor", {})
            
            # åŒ—å‘èµ„é‡‘åˆ†æ
            north_net = flow_data.get("hsgt_net_amount", 0)
            hk_net = flow_data.get("hk_net_amount", 0)
            sg_net = flow_data.get("sg_net_amount", 0)
            
            capital_data["north_funds"] = {
                "total_net_inflow": north_net,
                "hk_net": hk_net,
                "sg_net": sg_net,
                "analysis": self._interpret_north_funds(north_net, hk_net, sg_net)
            }
            
            # èèµ„èåˆ¸åˆ†æ
            margin_info = flow_data.get("margin", {})
            if margin_info:
                capital_data["margin_trading"] = {
                    "balance": margin_info.get("margin_balance", 0),
                    "daily_change": margin_info.get("margin_change", 0),
                    "buy_amount": margin_info.get("buy_amount", 0),
                    "analysis": self._interpret_margin_trading(margin_info)
                }
            
            # ä¸»åŠ›èµ„é‡‘åˆ†æ
            main_flow = flow_data.get("main_flow", {})
            if main_flow:
                capital_data["main_funds"] = {
                    "net_inflow": main_flow.get("main_net_inflow", 0),
                    "super_large": main_flow.get("super_large_net", 0),
                    "large": main_flow.get("large_net", 0),
                    "analysis": self._interpret_main_funds(main_flow)
                }
            
            # SHIBORåˆ©ç‡åˆ†æ
            if shibor_data:
                capital_data["shibor_rates"] = {
                    "overnight": shibor_data.get("on"),
                    "one_week": shibor_data.get("1w"), 
                    "analysis": self._interpret_shibor_rates(shibor_data)
                }
            
            return capital_data
            
        except Exception as e:
            logger.error(f"èµ„é‡‘æµå‘åˆ†æå¤±è´¥: {e}")
            return {"error": "èµ„é‡‘æµå‘æ•°æ®æš‚æ—¶æ— æ³•åˆ†æ"}
    
    def _analyze_index_structure(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææŒ‡æ•°æ¿å—ç»“æ„ - ä¸»è¦æŒ‡æ•°è¡¨ç°ã€è¡Œä¸šè½®åŠ¨"""
        try:
            structure_data = {}
            indices = market_data.get("indices", [])
            sectors = market_data.get("sectors", [])
            
            # ä¸»è¦æŒ‡æ•°è¡¨ç°åˆ†æ
            index_performance = []
            for idx in indices[:5]:  # å–å‰5ä¸ªä¸»è¦æŒ‡æ•°
                if idx.get("pct_chg") is not None:
                    index_name = self._get_index_name(idx.get("ts_code", ""))
                    index_performance.append({
                        "name": index_name,
                        "code": idx.get("ts_code"),
                        "close": idx.get("close"),
                        "change": idx.get("pct_chg"),
                        "strength": self._classify_index_strength(idx.get("pct_chg", 0))
                    })
            
            structure_data["index_performance"] = {
                "indices": index_performance,
                "analysis": self._interpret_index_divergence(index_performance)
            }
            
            # è¡Œä¸šæ¿å—è½®åŠ¨åˆ†æ
            if sectors:
                top_sectors = sectors[:5]  # æ¶¨å¹…å‰5
                bottom_sectors = sectors[-5:]  # è·Œå¹…å‰5ï¼ˆæœ€å5ä¸ªï¼‰
                
                structure_data["sector_rotation"] = {
                    "leading_sectors": top_sectors,
                    "lagging_sectors": bottom_sectors,
                    "analysis": self._interpret_sector_rotation(top_sectors, bottom_sectors)
                }
                
                # æ¿å—å¼ºåº¦åˆ†å¸ƒ
                structure_data["sector_distribution"] = self._analyze_sector_distribution(sectors)
            
            return structure_data
            
        except Exception as e:
            logger.error(f"æŒ‡æ•°æ¿å—ç»“æ„åˆ†æå¤±è´¥: {e}")
            return {"error": "æŒ‡æ•°æ¿å—æ•°æ®æš‚æ—¶æ— æ³•åˆ†æ"}
    
    def _analyze_macro_environment(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå®è§‚å¤–éƒ¨ç¯å¢ƒ - æ±‡ç‡ã€å¤§å®—å•†å“ã€æµ·å¤–å¸‚åœº"""
        try:
            macro_data = {}
            macro_indicators = market_data.get("macro_indicators", {})
            
            # æ±‡ç‡åˆ†æ
            usd_cny = macro_indicators.get("usd_cny")
            if usd_cny:
                macro_data["forex"] = {
                    "usd_cny": usd_cny,
                    "analysis": self._interpret_forex(usd_cny)
                }
            
            # å¤§å®—å•†å“åˆ†æ 
            oil_price = macro_indicators.get("oil_price")
            oil_change = macro_indicators.get("oil_change")
            gold_price = macro_indicators.get("gold_price") 
            gold_change = macro_indicators.get("gold_change")
            
            if oil_price is not None:
                macro_data["commodities"] = {
                    "oil": {
                        "price": oil_price,
                        "change": oil_change,
                        "impact": self._interpret_oil_impact(oil_change)
                    },
                    "gold": {
                        "price": gold_price, 
                        "change": gold_change,
                        "impact": self._interpret_gold_impact(gold_change)
                    },
                    "analysis": self._interpret_commodities_impact(oil_change, gold_change)
                }
            
            # å®è§‚ç¯å¢ƒç»¼åˆè¯„ä¼°
            macro_data["environment_assessment"] = self._assess_macro_environment(macro_indicators)
            
            return macro_data
            
        except Exception as e:
            logger.error(f"å®è§‚ç¯å¢ƒåˆ†æå¤±è´¥: {e}")
            return {"error": "å®è§‚ç¯å¢ƒæ•°æ®æš‚æ—¶æ— æ³•åˆ†æ"}
    
    def _analyze_news_announcements(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå…¬å‘Šæ–°é—» - é‡è¦å…¬å‘Šã€æ”¿ç­–æ–°é—»å½±å“"""
        try:
            news_data = {}
            
            # é‡è¦å…¬å‘Šåˆ†æ
            announcements = market_data.get("announcements", [])
            if announcements:
                positive_count = len([ann for ann in announcements if ann.get("impact") == "positive"])
                negative_count = len([ann for ann in announcements if ann.get("impact") == "negative"])
                
                news_data["important_announcements"] = {
                    "total_count": len(announcements),
                    "positive_count": positive_count,
                    "negative_count": negative_count,
                    "key_announcements": announcements[:3],  # å‰3ä¸ªé‡è¦å…¬å‘Š
                    "analysis": self._interpret_announcements_impact(announcements)
                }
            
            # æ”¿ç­–æ–°é—»åˆ†æ
            policy_news = market_data.get("policy_news", [])
            if policy_news:
                policy_impact_score = sum([news.get("impact_score", 0) for news in policy_news]) / len(policy_news)
                
                news_data["policy_news"] = {
                    "total_count": len(policy_news),
                    "average_impact": round(policy_impact_score, 1),
                    "key_policies": policy_news[:3],  # å‰3ä¸ªé‡è¦æ”¿ç­–
                    "analysis": self._interpret_policy_impact(policy_news)
                }
            
            # é‡è¦æ–°é—»æ ‡é¢˜
            major_news = market_data.get("major_news", [])
            if major_news:
                news_data["major_headlines"] = {
                    "headlines": major_news[:5],  # å‰5ä¸ªé‡è¦æ–°é—»
                    "analysis": self._interpret_news_sentiment(major_news)
                }
            
            return news_data
            
        except Exception as e:
            logger.error(f"æ–°é—»å…¬å‘Šåˆ†æå¤±è´¥: {e}")
            return {"error": "æ–°é—»å…¬å‘Šæ•°æ®æš‚æ—¶æ— æ³•åˆ†æ"}
    
    def _generate_overall_assessment(self, market_data: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°å’Œæ“ä½œå»ºè®®"""
        try:
            # è®¡ç®—ç»¼åˆè¯„åˆ† (1-10åˆ†)
            overall_score = self._calculate_overall_score(analysis)
            
            # ç”Ÿæˆå¸‚åœºçŠ¶æ€æè¿°
            market_state = self._determine_market_state(overall_score, market_data)
            
            # ç”Ÿæˆæ“ä½œå»ºè®®
            operation_advice = self._generate_operation_advice(overall_score, analysis)
            
            # é£é™©æç¤º
            risk_warnings = self._generate_risk_warnings(analysis)
            
            return {
                "overall_score": overall_score,
                "market_state": market_state,
                "operation_advice": operation_advice,
                "risk_warnings": risk_warnings,
                "confidence_level": self._calculate_confidence_level(analysis)
            }
            
        except Exception as e:
            logger.error(f"ç»¼åˆè¯„ä¼°ç”Ÿæˆå¤±è´¥: {e}")
            return {"error": "ç»¼åˆè¯„ä¼°æš‚æ—¶æ— æ³•ç”Ÿæˆ"}
    
    # ============= è§£è¯»è¾…åŠ©å‡½æ•° =============
    
    def _interpret_up_down_ratio(self, up_ratio: float) -> str:
        """è§£è¯»æ¶¨è·Œæ¯”ä¾‹"""
        if up_ratio >= 70:
            return f"æ¶¨è·Œæ¯”è¾¾{up_ratio}%ï¼Œå¸‚åœºæƒ…ç»ªæåº¦ä¹è§‚ï¼Œå¤šå¤´å¼ºåŠ¿ä¸»å¯¼ï¼Œèµšé’±æ•ˆåº”çªå‡º"
        elif up_ratio >= 60:
            return f"æ¶¨è·Œæ¯”ä¸º{up_ratio}%ï¼Œå¸‚åœºåæš–ï¼Œå¤šå¤´å ä¼˜ï¼Œä¸ªè‚¡è¡¨ç°æ´»è·ƒ"
        elif up_ratio >= 50:
            return f"æ¶¨è·Œæ¯”ä¸º{up_ratio}%ï¼Œå¸‚åœºå¹³è¡¡åå¼ºï¼Œç»“æ„æ€§æœºä¼šè¾ƒå¤š"
        elif up_ratio >= 40:
            return f"æ¶¨è·Œæ¯”ä¸º{up_ratio}%ï¼Œå¸‚åœºåˆ†åŒ–æ˜æ˜¾ï¼Œæ“ä½œéš¾åº¦åŠ å¤§"
        elif up_ratio >= 30:
            return f"æ¶¨è·Œæ¯”ä»…{up_ratio}%ï¼Œå¸‚åœºåå†·ï¼Œç©ºå¤´å‹åŠ›è¾ƒå¤§"
        else:
            return f"æ¶¨è·Œæ¯”ä»…{up_ratio}%ï¼Œå¸‚åœºæåº¦ä½è¿·ï¼Œå»ºè®®è°¨æ…è§‚æœ›"
    
    def _interpret_limit_boards(self, limit_up: int, limit_down: int) -> str:
        """è§£è¯»æ¶¨åœè·Œåœæƒ…å†µ"""
        if limit_up > 50:
            return f"æ¶¨åœæ¿å¤šè¾¾{limit_up}å®¶ï¼Œå¸‚åœºæƒ…ç»ªç«çˆ†ï¼Œé¢˜æç‚’ä½œæ´»è·ƒ"
        elif limit_up > 20:
            return f"æ¶¨åœæ¿{limit_up}å®¶ï¼Œå¸‚åœºæœ‰ä¸€å®šçƒ­åº¦ï¼Œå…³æ³¨æ¿å—è½®åŠ¨"
        elif limit_up > 10:
            return f"æ¶¨åœæ¿{limit_up}å®¶ï¼Œå¸‚åœºæ¸©å’Œæ´»è·ƒï¼Œä¸ªè‚¡æœºä¼šä¸å°‘"
        elif limit_up > 0:
            return f"æ¶¨åœæ¿{limit_up}å®¶ï¼Œå¸‚åœºè¡¨ç°å¹³æ·¡ï¼Œç¼ºä¹æŒç»­çƒ­ç‚¹"
        else:
            if limit_down > 10:
                return f"æ— æ¶¨åœè‚¡ï¼Œè·Œåœ{limit_down}å®¶ï¼Œå¸‚åœºææ…Œæƒ…ç»ªè¾ƒé‡"
            else:
                return "æ— æ¶¨åœè‚¡ï¼Œå¸‚åœºç¼ºä¹èµšé’±æ•ˆåº”ï¼Œè§‚æœ›æƒ…ç»ªæµ“åš"
    
    def _interpret_market_cap_performance(self, large: int, mid: int, small: int) -> str:
        """è§£è¯»ä¸åŒå¸‚å€¼è‚¡ç¥¨è¡¨ç°"""
        total = large + mid + small
        if total == 0:
            return "å¸‚å€¼åˆ†å¸ƒæ•°æ®ä¸è¶³"
        
        large_pct = large / total * 100
        small_pct = small / total * 100
        
        if large_pct > 50:
            return f"å¤§ç›˜è‚¡é¢†æ¶¨å æ¯”{large_pct:.1f}%ï¼Œä»·å€¼æŠ•èµ„é£æ ¼å ä¸»å¯¼ï¼Œå¸‚åœºåå‘ç¨³å¥"
        elif small_pct > 50:
            return f"å°ç›˜è‚¡æ´»è·ƒå æ¯”{small_pct:.1f}%ï¼Œé¢˜æè‚¡è¡¨ç°çªå‡ºï¼ŒæŠ•æœºæƒ…ç»ªè¾ƒæµ“"
        else:
            return f"å¤§ä¸­å°ç›˜è¡¨ç°å‡è¡¡ï¼Œå¸‚åœºé£æ ¼è¾ƒä¸ºå¹³è¡¡ï¼Œç»“æ„æ€§æœºä¼šå¹¶å­˜"
    
    def _interpret_north_funds(self, total_net: float, hk_net: float, sg_net: float) -> str:
        """è§£è¯»åŒ—å‘èµ„é‡‘"""
        if total_net > 100:
            return f"åŒ—å‘èµ„é‡‘å¤§å¹…å‡€æµå…¥{total_net:.1f}äº¿ï¼Œå¤–èµ„åšå®šçœ‹å¤šAè‚¡ï¼Œé‡ç‚¹å…³æ³¨å¤–èµ„é‡ä»“è‚¡"
        elif total_net > 50:
            return f"åŒ—å‘èµ„é‡‘å‡€æµå…¥{total_net:.1f}äº¿ï¼Œå¤–èµ„æ€åº¦åç§¯æï¼Œå¢å¼ºå¸‚åœºä¿¡å¿ƒ"
        elif total_net > 0:
            return f"åŒ—å‘èµ„é‡‘å°å¹…å‡€æµå…¥{total_net:.1f}äº¿ï¼Œå¤–èµ„ä¿æŒè°¨æ…ä¹è§‚"
        elif total_net > -50:
            return f"åŒ—å‘èµ„é‡‘å‡€æµå‡º{abs(total_net):.1f}äº¿ï¼Œå¤–èµ„è·åˆ©äº†ç»“ï¼Œéœ€å…³æ³¨è°ƒæ•´å‹åŠ›"
        else:
            return f"åŒ—å‘èµ„é‡‘å¤§å¹…å‡€æµå‡º{abs(total_net):.1f}äº¿ï¼Œå¤–èµ„é¿é™©æƒ…ç»ªå‡æ¸©ï¼Œè°¨æ…ä¸ºä¸»"
    
    def _interpret_margin_trading(self, margin_info: Dict) -> str:
        """è§£è¯»èèµ„èåˆ¸"""
        balance = margin_info.get("margin_balance", 0)
        change = margin_info.get("margin_change", 0)
        
        if change > 100:
            return f"ä¸¤èä½™é¢å¢åŠ {change:.1f}äº¿è‡³{balance:.1f}äº¿ï¼ŒæŠ•èµ„è€…åŠ æ æ†æ„æ„¿å¼ºçƒˆ"
        elif change > 0:
            return f"ä¸¤èä½™é¢å¢åŠ {change:.1f}äº¿ï¼Œèèµ„ä¹°å…¥æƒ…ç»ªæœ‰æ‰€å›å‡"
        elif change > -100:
            return f"ä¸¤èä½™é¢å‡å°‘{abs(change):.1f}äº¿ï¼ŒæŠ•èµ„è€…é™æ æ†æ“ä½œ"
        else:
            return f"ä¸¤èä½™é¢å¤§å¹…å‡å°‘{abs(change):.1f}äº¿ï¼Œå»æ æ†å‹åŠ›è¾ƒå¤§"
    
    def _interpret_main_funds(self, main_flow: Dict) -> str:
        """è§£è¯»ä¸»åŠ›èµ„é‡‘"""
        net_inflow = main_flow.get("main_net_inflow", 0)
        super_large = main_flow.get("super_large_net", 0)
        
        if net_inflow > 200:
            return f"ä¸»åŠ›èµ„é‡‘å‡€æµå…¥{net_inflow:.1f}äº¿ï¼Œæœºæ„å¤§ä¸¾å»ºä»“ï¼Œçœ‹å¥½åå¸‚"
        elif net_inflow > 100:
            return f"ä¸»åŠ›èµ„é‡‘å‡€æµå…¥{net_inflow:.1f}äº¿ï¼Œèµ„é‡‘é¢è¾ƒä¸ºæ´»è·ƒ"
        elif net_inflow > 0:
            return f"ä¸»åŠ›èµ„é‡‘å°å¹…å‡€æµå…¥{net_inflow:.1f}äº¿ï¼Œå¢é‡èµ„é‡‘è°¨æ…å…¥åœº"
        else:
            return f"ä¸»åŠ›èµ„é‡‘å‡€æµå‡º{abs(net_inflow):.1f}äº¿ï¼Œæœºæ„å‡ä»“æ˜æ˜¾"
    
    def _calculate_emotion_score(self, up_ratio: float, avg_change: float, limit_up: int, limit_down: int) -> float:
        """è®¡ç®—æƒ…ç»ªè¯„åˆ†"""
        score = 5.0  # åŸºç¡€åˆ†
        
        # æ¶¨è·Œæ¯”ä¾‹å½±å“ (æƒé‡40%)
        if up_ratio >= 70:
            score += 2.0
        elif up_ratio >= 60:
            score += 1.5
        elif up_ratio >= 50:
            score += 0.5
        elif up_ratio >= 40:
            score -= 0.5
        elif up_ratio >= 30:
            score -= 1.5
        else:
            score -= 2.0
            
        # å¹³å‡æ¶¨è·Œå¹…å½±å“ (æƒé‡30%)
        if avg_change > 2:
            score += 1.5
        elif avg_change > 1:
            score += 1.0
        elif avg_change > 0:
            score += 0.5
        elif avg_change > -1:
            score -= 0.5
        else:
            score -= 1.0
            
        # æ¶¨è·Œåœå½±å“ (æƒé‡30%)
        if limit_up > 50:
            score += 1.0
        elif limit_up > 20:
            score += 0.5
        elif limit_down > 20:
            score -= 1.0
        elif limit_down > 10:
            score -= 0.5
            
        return max(1.0, min(10.0, round(score, 1)))
    
    def _get_sentiment_description(self, score: float) -> str:
        """è·å–æƒ…ç»ªæè¿°"""
        if score >= 8.5:
            return "æåº¦ä¹è§‚"
        elif score >= 7.0:
            return "ä¹è§‚"
        elif score >= 6.0:
            return "åä¹è§‚"
        elif score >= 5.0:
            return "ä¸­æ€§"
        elif score >= 4.0:
            return "åè°¨æ…"
        elif score >= 3.0:
            return "è°¨æ…" 
        else:
            return "æåº¦è°¨æ…"
    
    def _get_index_name(self, code: str) -> str:
        """è·å–æŒ‡æ•°åç§°"""
        name_map = {
            "000001.SH": "ä¸Šè¯æŒ‡æ•°",
            "399001.SZ": "æ·±è¯æˆæŒ‡", 
            "399006.SZ": "åˆ›ä¸šæ¿æŒ‡",
            "000300.SH": "æ²ªæ·±300",
            "000016.SH": "ä¸Šè¯50"
        }
        return name_map.get(code, code)
    
    def _calculate_overall_score(self, analysis: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        try:
            score = 5.0  # åŸºç¡€åˆ†
            
            # å¸‚åœºæƒ…ç»ªè¯„åˆ† (æƒé‡25%)
            if "sentiment" in analysis and "emotion_score" in analysis["sentiment"]:
                emotion_score = analysis["sentiment"]["emotion_score"]
                score += (emotion_score - 5.0) * 0.25
            
            # èµ„é‡‘æµå‘è¯„åˆ† (æƒé‡25%) 
            if "capital" in analysis and "north_funds" in analysis["capital"]:
                north_net = analysis["capital"]["north_funds"].get("total_net_inflow", 0)
                if north_net > 100:
                    score += 1.0
                elif north_net > 50:
                    score += 0.5
                elif north_net < -50:
                    score -= 0.5
                elif north_net < -100:
                    score -= 1.0
            
            # å…¶ä»–ç»´åº¦æƒé‡è¾ƒå°ï¼Œæš‚æ—¶ç®€åŒ–å¤„ç†
            
            return max(1.0, min(10.0, round(score, 1)))
        except:
            return 5.0
    
    def _determine_market_state(self, score: float, market_data: Dict) -> str:
        """ç¡®å®šå¸‚åœºçŠ¶æ€"""
        if score >= 8.0:
            return "å¼ºåŠ¿ä¸Šæ¶¨"
        elif score >= 7.0:
            return "ç¨³æ­¥ä¸Šæ¶¨"
        elif score >= 6.0:
            return "éœ‡è¡åå¼º"
        elif score >= 5.0:
            return "éœ‡è¡æ•´ç†"
        elif score >= 4.0:
            return "éœ‡è¡åå¼±"
        elif score >= 3.0:
            return "å¼±åŠ¿è°ƒæ•´"
        else:
            return "æ·±åº¦è°ƒæ•´"
    
    def _generate_operation_advice(self, score: float, analysis: Dict) -> List[str]:
        """ç”Ÿæˆæ“ä½œå»ºè®®"""
        advice = []
        
        if score >= 8.0:
            advice.append("ğŸš€ å¸‚åœºå¼ºåŠ¿ï¼Œå»ºè®®é€‚åº¦åŠ ä»“ï¼Œä»“ä½å¯æå‡è‡³70-80%")
            advice.append("ğŸ“ˆ é‡ç‚¹å…³æ³¨é¢†æ¶¨æ¿å—çš„é¾™å¤´è‚¡ï¼Œç§¯æå‚ä¸")
            advice.append("âš¡ æŠŠæ¡çŸ­çº¿æœºä¼šï¼Œä½†æ³¨æ„åŠæ—¶æ­¢ç›ˆ")
        elif score >= 6.0:
            advice.append("ğŸ“Š å¸‚åœºåå¼ºï¼Œç»´æŒ60-70%ä»“ä½ï¼Œç¨³å¥æ“ä½œ")
            advice.append("ğŸ¯ é€‰æ‹©æ€§å‚ä¸çƒ­ç‚¹æ¿å—ï¼Œé¿å…ç›²ç›®è¿½é«˜")
            advice.append("ğŸ’¡ é€‚å½“é«˜æŠ›ä½å¸ï¼Œæ§åˆ¶é£é™©")
        elif score >= 4.0:
            advice.append("âš–ï¸ å¸‚åœºéœ‡è¡ï¼Œæ§åˆ¶ä»“ä½åœ¨40-50%")
            advice.append("ğŸ” ç­‰å¾…æ˜ç¡®ä¿¡å·ï¼Œè°¨æ…é€‰è‚¡")
            advice.append("ğŸ›¡ï¸ æ³¨é‡é˜²å¾¡ï¼Œå…³æ³¨ä½ä¼°å€¼å“ç§")
        else:
            advice.append("ğŸš¨ å¸‚åœºåå¼±ï¼Œé™ä½ä»“ä½è‡³30%ä»¥ä¸‹")
            advice.append("ğŸ’° ä¿æŒå……è¶³ç°é‡‘ï¼Œç­‰å¾…æœºä¼š")
            advice.append("ğŸ”„ é¿å…æŠ„åº•ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·")
        
        return advice
    
    def _generate_risk_warnings(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆé£é™©æç¤º"""
        warnings = []
        
        # æ ¹æ®åˆ†æç»“æœç”Ÿæˆé£é™©æç¤º
        try:
            if "sentiment" in analysis:
                emotion_score = analysis["sentiment"].get("emotion_score", 5)
                if emotion_score > 8:
                    warnings.append("âš ï¸ å¸‚åœºæƒ…ç»ªè¿‡çƒ­ï¼Œæ³¨æ„è·åˆ©å›åé£é™©")
                elif emotion_score < 3:
                    warnings.append("âš ï¸ å¸‚åœºæƒ…ç»ªä½è¿·ï¼Œç»§ç»­ä¸‹è·Œé£é™©è¾ƒå¤§")
            
            if "capital" in analysis and "north_funds" in analysis["capital"]:
                north_net = analysis["capital"]["north_funds"].get("total_net_inflow", 0)
                if north_net < -100:
                    warnings.append("âš ï¸ åŒ—å‘èµ„é‡‘å¤§å¹…æµå‡ºï¼Œå¤–èµ„å‡ä»“å‹åŠ›æ˜æ˜¾")
            
            if not warnings:
                warnings.append("âœ… å½“å‰å¸‚åœºé£é™©å¯æ§ï¼Œä¿æŒç†æ€§æŠ•èµ„")
                
        except:
            warnings.append("âš ï¸ é£é™©è¯„ä¼°æš‚æ—¶æ— æ³•å®Œæˆï¼Œè¯·ä¿æŒè°¨æ…")
        
        return warnings
    
    def _calculate_confidence_level(self, analysis: Dict) -> str:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        # æ ¹æ®æ•°æ®å®Œæ•´æ€§è®¡ç®—ç½®ä¿¡åº¦
        complete_dimensions = sum(1 for dim in ["sentiment", "capital", "structure", "macro", "news"] 
                                if dim in analysis and not isinstance(analysis[dim], dict) or "error" not in analysis[dim])
        
        confidence_pct = (complete_dimensions / 5.0) * 100
        
        if confidence_pct >= 80:
            return "é«˜ (æ•°æ®å®Œæ•´)"
        elif confidence_pct >= 60:
            return "ä¸­ç­‰ (éƒ¨åˆ†æ•°æ®ç¼ºå¤±)"
        else:
            return "è¾ƒä½ (æ•°æ®ä¸å®Œæ•´)"
    
    def _get_fallback_analysis(self) -> Dict[str, Any]:
        """è·å–åå¤‡åˆ†æç»“æœ"""
        return {
            "sentiment": {"error": "å¸‚åœºæƒ…ç»ªåˆ†ææš‚æ—¶ä¸å¯ç”¨"},
            "capital": {"error": "èµ„é‡‘æµå‘åˆ†ææš‚æ—¶ä¸å¯ç”¨"},
            "structure": {"error": "æ¿å—ç»“æ„åˆ†ææš‚æ—¶ä¸å¯ç”¨"},
            "macro": {"error": "å®è§‚ç¯å¢ƒåˆ†ææš‚æ—¶ä¸å¯ç”¨"},
            "news": {"error": "æ–°é—»åˆ†ææš‚æ—¶ä¸å¯ç”¨"},
            "summary": {
                "overall_score": 5.0,
                "market_state": "æ•°æ®ä¸è¶³",
                "operation_advice": ["ğŸ“Š æ•°æ®è·å–ä¸­ï¼Œè¯·ç¨åæŸ¥çœ‹åˆ†æç»“æœ"],
                "risk_warnings": ["âš ï¸ åˆ†ææ•°æ®ä¸å®Œæ•´ï¼Œè¯·è°¨æ…å‚è€ƒ"],
                "confidence_level": "è¾ƒä½ (æ•°æ®è·å–å¤±è´¥)"
            },
            "generated_at": dt.datetime.now().isoformat(),
            "error": "ç»¼åˆåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œæ­£åœ¨ä¿®å¤ä¸­..."
        }
    
    # ============= å…¶ä»–è¾…åŠ©è§£è¯»å‡½æ•° =============
    
    def _interpret_shibor_rates(self, shibor_data: Dict) -> str:
        """è§£è¯»SHIBORåˆ©ç‡"""
        overnight = shibor_data.get("on")
        one_week = shibor_data.get("1w")
        
        if overnight and one_week:
            if float(overnight) > 3.0:
                return f"éš”å¤œSHIBORè¾¾{overnight}%ï¼Œèµ„é‡‘é¢åç´§ï¼Œéœ€å…³æ³¨æµåŠ¨æ€§é£é™©"
            elif float(overnight) < 1.0:
                return f"éš”å¤œSHIBORä»…{overnight}%ï¼Œå¸‚åœºèµ„é‡‘å……è£•ï¼ŒæµåŠ¨æ€§å®½æ¾"
            else:
                return f"SHIBORåˆ©ç‡å¹³ç¨³ï¼Œéš”å¤œ{overnight}%ï¼Œèµ„é‡‘é¢ä¸­æ€§"
        return "SHIBORæ•°æ®æš‚æ—¶ä¸å¯ç”¨"
    
    def _interpret_forex(self, usd_cny: float) -> str:
        """è§£è¯»æ±‡ç‡å½±å“"""
        if usd_cny > 7.3:
            return f"äººæ°‘å¸ç›¸å¯¹åå¼±ï¼ˆ{usd_cny}ï¼‰ï¼Œæœ‰åˆ©äºå‡ºå£ä¼ä¸šï¼Œå…³æ³¨å¤–è´¸è‚¡"
        elif usd_cny < 7.0:
            return f"äººæ°‘å¸ç›¸å¯¹è¾ƒå¼ºï¼ˆ{usd_cny}ï¼‰ï¼Œåˆ©å¥½è¿›å£æ¶ˆè´¹ï¼Œå…³æ³¨å†…éœ€è‚¡"
        else:
            return f"æ±‡ç‡ç›¸å¯¹å¹³ç¨³ï¼ˆ{usd_cny}ï¼‰ï¼Œå¯¹å¸‚åœºå½±å“ä¸­æ€§"
    
    def _interpret_oil_impact(self, oil_change: float) -> str:
        """è§£è¯»åŸæ²¹ä»·æ ¼å½±å“"""
        if oil_change > 3:
            return "åŸæ²¹å¤§æ¶¨ï¼Œåˆ©å¥½çŸ³åŒ–ä¸Šæ¸¸ï¼Œåˆ©ç©ºä¸‹æ¸¸ç‚¼åŒ–"
        elif oil_change > 1:
            return "åŸæ²¹ä¸Šæ¶¨ï¼Œå…³æ³¨èƒ½æºæ¿å—æœºä¼š"
        elif oil_change < -3:
            return "åŸæ²¹å¤§è·Œï¼Œåˆ©å¥½ä¸‹æ¸¸åŒ–å·¥ï¼Œåˆ©ç©ºä¸Šæ¸¸å¼€é‡‡"
        elif oil_change < -1:
            return "åŸæ²¹ä¸‹è·Œï¼Œå…³æ³¨æˆæœ¬æ”¹å–„çš„åŒ–å·¥è‚¡"
        else:
            return "åŸæ²¹ä»·æ ¼å¹³ç¨³ï¼Œå½±å“ä¸­æ€§"
    
    def _interpret_gold_impact(self, gold_change: float) -> str:
        """è§£è¯»é»„é‡‘ä»·æ ¼å½±å“"""
        if gold_change > 2:
            return "é»„é‡‘å¤§æ¶¨ï¼Œé¿é™©æƒ…ç»ªå‡æ¸©ï¼Œå…³æ³¨è´µé‡‘å±è‚¡"
        elif gold_change > 0:
            return "é»„é‡‘ä¸Šæ¶¨ï¼Œå¸‚åœºé¿é™©éœ€æ±‚ä¸Šå‡"
        elif gold_change < -2:
            return "é»„é‡‘å¤§è·Œï¼Œé£é™©åå¥½å›å‡ï¼Œåˆ©å¥½æƒç›Šå¸‚åœº"
        else:
            return "é»„é‡‘ä»·æ ¼å¹³ç¨³"
    
    def _interpret_commodities_impact(self, oil_change: float, gold_change: float) -> str:
        """è§£è¯»å¤§å®—å•†å“ç»¼åˆå½±å“"""
        if oil_change > 2 and gold_change > 1:
            return "æ²¹ä»·é‡‘ä»·åŒæ¶¨ï¼Œé€šèƒ€é¢„æœŸå‡æ¸©ï¼Œå…³æ³¨å‘¨æœŸè‚¡å’Œé¿é™©å“ç§"
        elif oil_change > 2:
            return "æ²¹ä»·å¤§æ¶¨æ¨åŠ¨é€šèƒ€é¢„æœŸï¼Œå…³æ³¨ä¸Šæ¸¸èµ„æºè‚¡"
        elif gold_change > 2:
            return "é‡‘ä»·å¤§æ¶¨åæ˜ é¿é™©æƒ…ç»ªï¼Œå¸‚åœºé£é™©åå¥½ä¸‹é™"
        else:
            return "å¤§å®—å•†å“ä»·æ ¼ç›¸å¯¹å¹³ç¨³ï¼Œå¯¹å¸‚åœºå½±å“æœ‰é™"
    
    def _assess_macro_environment(self, macro_indicators: Dict) -> str:
        """è¯„ä¼°å®è§‚ç¯å¢ƒ"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®å¤šä¸ªå®è§‚æŒ‡æ ‡ç»¼åˆè¯„ä¼°
        return "å½“å‰å®è§‚ç¯å¢ƒæ•´ä½“ç¨³å®šï¼Œå¤–éƒ¨å› ç´ å½±å“å¯æ§"
    
    def _interpret_index_divergence(self, index_performance: List[Dict]) -> str:
        """è§£è¯»æŒ‡æ•°åˆ†åŒ–"""
        if not index_performance:
            return "æŒ‡æ•°è¡¨ç°æ•°æ®ä¸è¶³"
        
        changes = [idx["change"] for idx in index_performance if idx["change"] is not None]
        if not changes:
            return "æŒ‡æ•°æ¶¨è·Œæ•°æ®ä¸è¶³"
        
        max_change = max(changes)
        min_change = min(changes)
        divergence = max_change - min_change
        
        if divergence > 3:
            return f"æŒ‡æ•°åˆ†åŒ–æ˜æ˜¾ï¼Œæœ€å¤§åˆ†åŒ–è¾¾{divergence:.1f}%ï¼Œç»“æ„æ€§è¡Œæƒ…æ˜¾è‘—"
        elif divergence > 1:
            return f"æŒ‡æ•°è¡¨ç°æœ‰æ‰€åˆ†åŒ–ï¼Œåæ˜ ä¸åŒæ¿å—è½®åŠ¨"
        else:
            return f"ä¸»è¦æŒ‡æ•°åŒæ­¥æ€§è¾ƒå¼ºï¼Œå¸‚åœºè¡¨ç°ä¸€è‡´"
    
    def _interpret_sector_rotation(self, top_sectors: List, bottom_sectors: List) -> str:
        """è§£è¯»æ¿å—è½®åŠ¨"""
        if not top_sectors or not bottom_sectors:
            return "æ¿å—æ•°æ®ä¸è¶³"
        
        top_change = top_sectors[0].get("pct_chg", 0)
        bottom_change = bottom_sectors[0].get("pct_chg", 0)
        
        if top_change > 5:
            return f"{top_sectors[0]['name']}ç­‰å¼ºåŠ¿æ¿å—é¢†æ¶¨è¶…{top_change:.1f}%ï¼Œæ¿å—è½®åŠ¨æ˜æ˜¾"
        elif top_change > 2:
            return f"æ¿å—è½®åŠ¨æ­£å¸¸ï¼Œ{top_sectors[0]['name']}ç­‰æ¿å—è¡¨ç°ç›¸å¯¹è¾ƒå¥½"
        elif top_change < 0:
            return "ä¸»è¦æ¿å—æ™®éè°ƒæ•´ï¼Œå¸‚åœºç¼ºä¹è½®åŠ¨çƒ­ç‚¹"
        else:
            return "æ¿å—è¡¨ç°ç›¸å¯¹å¹³å‡ï¼Œç¼ºä¹æ˜æ˜¾ä¸»çº¿"
    
    def _analyze_sector_distribution(self, sectors: List) -> Dict:
        """åˆ†ææ¿å—å¼ºåº¦åˆ†å¸ƒ"""
        if not sectors:
            return {"error": "æ¿å—æ•°æ®ä¸è¶³"}
        
        positive = len([s for s in sectors if s.get("pct_chg", 0) > 0])
        negative = len([s for s in sectors if s.get("pct_chg", 0) < 0])
        neutral = len(sectors) - positive - negative
        
        return {
            "positive_sectors": positive,
            "negative_sectors": negative,
            "neutral_sectors": neutral,
            "strength_ratio": round(positive / len(sectors) * 100, 1) if sectors else 0
        }
    
    def _classify_index_strength(self, change: float) -> str:
        """åˆ†ç±»æŒ‡æ•°å¼ºåº¦"""
        if change > 2:
            return "å¼ºåŠ¿"
        elif change > 0:
            return "åå¼º"
        elif change > -2:
            return "åå¼±"
        else:
            return "å¼±åŠ¿"
    
    def _interpret_announcements_impact(self, announcements: List) -> str:
        """è§£è¯»å…¬å‘Šå½±å“"""
        if not announcements:
            return "ä»Šæ—¥é‡è¦å…¬å‘Šè¾ƒå°‘"
        
        positive_count = len([ann for ann in announcements if ann.get("impact") == "positive"])
        total_count = len(announcements)
        
        if positive_count / total_count > 0.7:
            return f"ä»Šæ—¥{total_count}æ¡é‡è¦å…¬å‘Šä¸­{positive_count}æ¡ä¸ºåˆ©å¥½ï¼Œæ•´ä½“åæ­£é¢"
        elif positive_count / total_count < 0.3:
            return f"ä»Šæ—¥é‡è¦å…¬å‘Šåè´Ÿé¢ï¼Œéœ€å…³æ³¨ç›¸å…³ä¸ªè‚¡é£é™©"
        else:
            return f"ä»Šæ—¥å…¬å‘Šå½±å“åä¸­æ€§ï¼Œæ­£è´Ÿé¢æ¶ˆæ¯å¹¶å­˜"
    
    def _interpret_policy_impact(self, policy_news: List) -> str:
        """è§£è¯»æ”¿ç­–å½±å“"""
        if not policy_news:
            return "ä»Šæ—¥æ”¿ç­–é¢ç›¸å¯¹å¹³é™"
        
        avg_impact = sum([news.get("impact_score", 0) for news in policy_news]) / len(policy_news)
        
        if avg_impact > 7:
            return f"é‡è¦æ”¿ç­–å¯†é›†å‡ºå°ï¼Œå¹³å‡å½±å“è¯„åˆ†{avg_impact:.1f}ï¼Œæ”¿ç­–é¢åæš–"
        elif avg_impact > 5:
            return f"æ”¿ç­–é¢ä¸­æ€§åå¥½ï¼Œå…³æ³¨æ”¿ç­–å—ç›Šæ¿å—"
        else:
            return f"æ”¿ç­–å½±å“ç›¸å¯¹æœ‰é™ï¼Œå¸‚åœºä¸»è¦çœ‹åŸºæœ¬é¢"
    
    def _interpret_news_sentiment(self, major_news: List) -> str:
        """è§£è¯»æ–°é—»æƒ…ç»ª"""
        if not major_news:
            return "ä»Šæ—¥é‡è¦æ–°é—»è¾ƒå°‘"
        
        # ç®€å•çš„æƒ…ç»ªåˆ†æï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨NLPæŠ€æœ¯ï¼‰
        return f"ä»Šæ—¥{len(major_news)}æ¡é‡è¦æ–°é—»ï¼Œæ•´ä½“æ°›å›´éœ€ç»“åˆå…·ä½“å†…å®¹åˆ¤æ–­"
    
    # ============= æ–°å¢åŠŸèƒ½ï¼šæ™ºèƒ½åŒ–åˆ†æ =============
    
    def _analyze_market_hotspots(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """å®æ—¶çƒ­ç‚¹è¿½è¸ªåˆ†æ"""
        try:
            hotspots = {}
            
            # çƒ­é—¨æ¿å—åˆ†æ
            sectors = market_data.get("sectors", [])
            if sectors:
                hot_sectors = sectors[:3]  # å–å‰3ä¸ªçƒ­é—¨æ¿å—
                hotspots["hot_sectors"] = {
                    "sectors": hot_sectors,
                    "momentum_score": self._calculate_sector_momentum(hot_sectors),
                    "sustainability": self._assess_sector_sustainability(hot_sectors),
                    "analysis": self._interpret_hot_sectors(hot_sectors)
                }
            
            # æ¦‚å¿µè½®åŠ¨åˆ†æ
            concepts = market_data.get("concepts", [])
            if concepts:
                hot_concepts = concepts[:5]  # å–å‰5ä¸ªçƒ­é—¨æ¦‚å¿µ
                hotspots["concept_rotation"] = {
                    "concepts": hot_concepts,
                    "rotation_speed": self._calculate_rotation_speed(concepts),
                    "analysis": self._interpret_concept_rotation(hot_concepts)
                }
            
            # æ–°é—»é©±åŠ¨è‚¡ç¥¨
            news_driven = self._extract_news_driven_stocks(market_data)
            if news_driven:
                hotspots["news_driven"] = {
                    "stocks": news_driven,
                    "impact_analysis": self._analyze_news_impact(news_driven)
                }
            
            # åŠ¨é‡åˆ†æ
            momentum_data = self._calculate_momentum_indicators(market_data)
            hotspots["momentum_analysis"] = momentum_data
            
            return hotspots
            
        except Exception as e:
            logger.error(f"çƒ­ç‚¹è¿½è¸ªåˆ†æå¤±è´¥: {e}")
            return {"error": "çƒ­ç‚¹è¿½è¸ªæ•°æ®æš‚æ—¶ä¸å¯ç”¨"}
    
    def _generate_market_alerts(self, analysis: Dict[str, Any]) -> List[Dict]:
        """æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ"""
        alerts = []
        
        try:
            # æµåŠ¨æ€§é¢„è­¦
            if "capital" in analysis and "shibor_rates" in analysis["capital"]:
                overnight_rate = analysis["capital"]["shibor_rates"].get("overnight")
                if overnight_rate and float(overnight_rate) > 3.5:
                    alerts.append({
                        "type": "liquidity_risk",
                        "level": "high",
                        "message": f"éš”å¤œSHIBORå¼‚å¸¸å‡é«˜è‡³{overnight_rate}%ï¼Œå…³æ³¨æµåŠ¨æ€§é£é™©",
                        "action": "é™ä½ä»“ä½ï¼Œä¿æŒå……è¶³ç°é‡‘"
                    })
            
            # æƒ…ç»ªæç«¯é¢„è­¦
            if "sentiment" in analysis:
                emotion_score = analysis["sentiment"].get("emotion_score", 5)
                if emotion_score > 9:
                    alerts.append({
                        "type": "sentiment_extreme_high",
                        "level": "medium",
                        "message": f"å¸‚åœºæƒ…ç»ªè¿‡çƒ­(è¯„åˆ†{emotion_score})ï¼Œæ³¨æ„å›è°ƒé£é™©",
                        "action": "é€‚åº¦è·åˆ©äº†ç»“ï¼Œæ§åˆ¶ä»“ä½"
                    })
                elif emotion_score < 2:
                    alerts.append({
                        "type": "sentiment_extreme_low",
                        "level": "high",
                        "message": f"å¸‚åœºæƒ…ç»ªæåº¦ä½è¿·(è¯„åˆ†{emotion_score})ï¼Œç»§ç»­ä¸‹è·Œé£é™©è¾ƒå¤§",
                        "action": "è°¨æ…è§‚æœ›ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·"
                    })
            
            # èµ„é‡‘æµå‘é¢„è­¦
            if "capital" in analysis and "north_funds" in analysis["capital"]:
                north_net = analysis["capital"]["north_funds"].get("total_net_inflow", 0)
                if north_net < -200:
                    alerts.append({
                        "type": "capital_outflow",
                        "level": "high",
                        "message": f"åŒ—å‘èµ„é‡‘å¤§å¹…æµå‡º{abs(north_net):.1f}äº¿ï¼Œå¤–èµ„å‡ä»“å‹åŠ›æ˜æ˜¾",
                        "action": "å…³æ³¨å¤–èµ„é‡ä»“è‚¡è°ƒæ•´é£é™©"
                    })
            
            # æŠ€æœ¯é¢é¢„è­¦
            if "structure" in analysis and "index_performance" in analysis["structure"]:
                indices = analysis["structure"]["index_performance"].get("indices", [])
                if indices:
                    main_index_change = indices[0].get("change", 0)
                    if main_index_change < -3:
                        alerts.append({
                            "type": "technical_breakdown",
                            "level": "medium",
                            "message": f"ä¸»è¦æŒ‡æ•°å¤§è·Œ{abs(main_index_change):.1f}%ï¼ŒæŠ€æœ¯é¢èµ°å¼±",
                            "action": "ç­‰å¾…æŠ€æœ¯ä¿®å¤ä¿¡å·ï¼Œé¿å…ç›²ç›®æŠ„åº•"
                        })
            
            # æ¿å—è½®åŠ¨é¢„è­¦
            if "hotspots" in analysis and "hot_sectors" in analysis["hotspots"]:
                momentum_score = analysis["hotspots"]["hot_sectors"].get("momentum_score", 0)
                if momentum_score < 3:
                    alerts.append({
                        "type": "rotation_stagnation",
                        "level": "low",
                        "message": "æ¿å—è½®åŠ¨åœæ»ï¼Œå¸‚åœºç¼ºä¹æ˜ç¡®ä¸»çº¿",
                        "action": "ç­‰å¾…æ–°çƒ­ç‚¹å‡ºç°ï¼Œä¿æŒè€å¿ƒ"
                    })
            
            # é»˜è®¤æ— é£é™©æç¤º
            if not alerts:
                alerts.append({
                    "type": "normal",
                    "level": "low",
                    "message": "å½“å‰å¸‚åœºé£é™©å¯æ§ï¼Œä¿æŒç†æ€§æŠ•èµ„",
                    "action": "ç»§ç»­å…³æ³¨å¸‚åœºå˜åŒ–ï¼Œé€‚åº¦å‚ä¸"
                })
            
            return alerts
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½é¢„è­¦ç³»ç»Ÿé”™è¯¯: {e}")
            return [{
                "type": "system_error",
                "level": "low",
                "message": "é¢„è­¦ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨",
                "action": "è¯·æ‰‹åŠ¨å…³æ³¨å¸‚åœºé£é™©"
            }]
    
    def _calculate_fear_greed_index(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ææ…Œè´ªå©ªæŒ‡æ•° (0-100åˆ†)"""
        try:
            score = 50  # åŸºç¡€åˆ†æ•°
            components = {}
            
            # 1. å¸‚åœºæƒ…ç»ª (30%æƒé‡)
            if "sentiment" in analysis:
                emotion_score = analysis["sentiment"].get("emotion_score", 5)
                sentiment_component = ((emotion_score - 5) / 5) * 30
                score += sentiment_component
                components["market_sentiment"] = {
                    "value": emotion_score,
                    "weight": 30,
                    "contribution": sentiment_component
                }
            
            # 2. èµ„é‡‘æµå‘ (25%æƒé‡)
            if "capital" in analysis and "north_funds" in analysis["capital"]:
                north_net = analysis["capital"]["north_funds"].get("total_net_inflow", 0)
                # å°†èµ„é‡‘æµå‘è½¬åŒ–ä¸º0-100åˆ†
                capital_score = min(100, max(0, 50 + north_net / 10))  # æ¯10äº¿å¯¹åº”1åˆ†
                capital_component = ((capital_score - 50) / 50) * 25
                score += capital_component
                components["capital_flow"] = {
                    "value": north_net,
                    "weight": 25,
                    "contribution": capital_component
                }
            
            # 3. æ³¢åŠ¨ç‡æŒ‡æ ‡ (20%æƒé‡) - æ¨¡æ‹ŸVIX
            vix_score = self._calculate_vix_equivalent(analysis)
            vix_component = ((50 - vix_score) / 50) * 20  # VIXè¶Šé«˜è´ªå©ªæŒ‡æ•°è¶Šä½
            score += vix_component
            components["volatility"] = {
                "value": vix_score,
                "weight": 20,
                "contribution": vix_component
            }
            
            # 4. æ¿å—è½®åŠ¨ (15%æƒé‡)
            if "structure" in analysis and "sector_rotation" in analysis["structure"]:
                rotation_strength = self._assess_rotation_strength(analysis["structure"]["sector_rotation"])
                rotation_component = ((rotation_strength - 50) / 50) * 15
                score += rotation_component
                components["sector_rotation"] = {
                    "value": rotation_strength,
                    "weight": 15,
                    "contribution": rotation_component
                }
            
            # 5. æ–°é—»æƒ…ç»ª (10%æƒé‡)
            if "news" in analysis:
                news_sentiment = self._calculate_news_sentiment_score(analysis["news"])
                news_component = ((news_sentiment - 50) / 50) * 10
                score += news_component
                components["news_sentiment"] = {
                    "value": news_sentiment,
                    "weight": 10,
                    "contribution": news_component
                }
            
            # ç¡®ä¿åˆ†æ•°åœ¨ 0-100 èŒƒå›´å†…
            final_score = max(0, min(100, round(score, 1)))
            
            return {
                "score": final_score,
                "level": self._get_fear_greed_level(final_score),
                "components": components,
                "interpretation": self._interpret_fear_greed_index(final_score)
            }
            
        except Exception as e:
            logger.error(f"ææ…Œè´ªå©ªæŒ‡æ•°è®¡ç®—å¤±è´¥: {e}")
            return {
                "score": 50,
                "level": "ä¸­æ€§",
                "components": {},
                "interpretation": "ææ…Œè´ªå©ªæŒ‡æ•°æš‚æ—¶æ— æ³•è®¡ç®—"
            }
    
    def _generate_intelligent_narrative(self, analysis: Dict[str, Any]) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½åŒ–å¸‚åœºè§£è¯»å™è¿°"""
        try:
            # æ„å»ºç»“æ„åŒ–çš„åˆ†ææç¤ºè¯
            prompt_data = self._build_analysis_prompt_data(analysis)
            
            # è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½è§£è¯»
            narrative = self._call_llm_for_analysis(prompt_data)
            
            return narrative
            
        except Exception as e:
            logger.error(f"LLMæ™ºèƒ½è§£è¯»ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_narrative(analysis)
    
    # ============= è¾…åŠ©å‡½æ•° =============
    
    def _calculate_sector_momentum(self, sectors: List[Dict]) -> float:
        """è®¡ç®—æ¿å—åŠ¨é‡è¯„åˆ†"""
        if not sectors:
            return 0
        
        momentum = 0
        for sector in sectors[:3]:
            change = sector.get("pct_chg", 0)
            if change > 5:
                momentum += 3
            elif change > 3:
                momentum += 2
            elif change > 1:
                momentum += 1
        
        return min(10, momentum)
    
    def _assess_sector_sustainability(self, sectors: List[Dict]) -> str:
        """è¯„ä¼°æ¿å—æŒç»­æ€§"""
        if not sectors:
            return "æ•°æ®ä¸è¶³"
        
        top_change = sectors[0].get("pct_chg", 0)
        if top_change > 8:
            return "çŸ­çº¿æ€§è´¨æ˜æ˜¾ï¼ŒæŒç»­æ€§å¾…è§‚å¯Ÿ"
        elif top_change > 5:
            return "æœ‰ä¸€å®šæŒç»­æ€§ï¼Œå…³æ³¨é‡èƒ½é…åˆ"
        elif top_change > 2:
            return "æŒç»­æ€§è¾ƒå¥½ï¼Œå¯é‡ç‚¹å…³æ³¨"
        else:
            return "åŠ¨èƒ½ä¸è¶³ï¼ŒæŒç»­æ€§å¼±"
    
    def _interpret_hot_sectors(self, sectors: List[Dict]) -> str:
        """è§£è¯»çƒ­é—¨æ¿å—"""
        if not sectors:
            return "ä»Šæ—¥æ— æ˜æ˜¾çƒ­ç‚¹æ¿å—"
        
        top_sector = sectors[0]
        sector_name = top_sector.get("name", "æœªçŸ¥")
        change = top_sector.get("pct_chg", 0)
        
        if change > 6:
            return f"{sector_name}æ¿å—å¼ºåŠ¿çˆ†å‘ï¼Œæ¶¨å¹…è¾¾{change:.1f}%ï¼Œå¸‚åœºçƒ­ç‚¹é›†ä¸­"
        elif change > 3:
            return f"{sector_name}æ¿å—è¡¨ç°æ´»è·ƒï¼Œæ¶¨å¹…{change:.1f}%ï¼Œå¸¦åŠ¨ç›¸å…³æ¦‚å¿µ"
        else:
            return f"{sector_name}æ¿å—æ¸©å’Œä¸Šæ¶¨ï¼Œå¸‚åœºè½®åŠ¨æœ‰åº"
    
    def _calculate_rotation_speed(self, concepts: List[Dict]) -> str:
        """è®¡ç®—è½®åŠ¨é€Ÿåº¦"""
        if not concepts or len(concepts) < 5:
            return "æ•°æ®ä¸è¶³"
        
        top_changes = [c.get("pct_chg", 0) for c in concepts[:5]]
        avg_change = sum(top_changes) / len(top_changes)
        max_change = max(top_changes)
        
        if max_change > 10:
            return "æå¿« - çˆ†å‘æ€§çƒ­ç‚¹"
        elif avg_change > 5:
            return "è¾ƒå¿« - æ¿å—è½®åŠ¨æ´»è·ƒ"
        elif avg_change > 2:
            return "æ­£å¸¸ - ç¨³å¥è½®åŠ¨"
        else:
            return "è¾ƒæ…¢ - è½®åŠ¨åœæ»"
    
    def _interpret_concept_rotation(self, concepts: List[Dict]) -> str:
        """è§£è¯»æ¦‚å¿µè½®åŠ¨"""
        if not concepts:
            return "æ¦‚å¿µæ¿å—è¡¨ç°å¹³æ·¡"
        
        hot_concepts = [c.get("name", "") for c in concepts[:3]]
        concept_names = "ã€".join(hot_concepts)
        
        return f"ä»Šæ—¥çƒ­é—¨æ¦‚å¿µä¸º{concept_names}ç­‰ï¼Œèµ„é‡‘è½®åŠ¨æ˜æ˜¾"
    
    def _extract_news_driven_stocks(self, market_data: Dict) -> List[Dict]:
        """æå–æ–°é—»é©±åŠ¨è‚¡ç¥¨"""
        # æ¨¡æ‹Ÿæ–°é—»é©±åŠ¨è‚¡ç¥¨æ•°æ®
        return [
            {"ts_code": "000001.SZ", "name": "å¹³å®‰é“¶è¡Œ", "news_type": "ä¸šç»©é¢„å‘Š", "impact": "positive"},
            {"ts_code": "600519.SH", "name": "è´µå·èŒ…å°", "news_type": "æœºæ„è°ƒç ”", "impact": "positive"}
        ]
    
    def _analyze_news_impact(self, news_driven: List[Dict]) -> str:
        """åˆ†ææ–°é—»å½±å“"""
        if not news_driven:
            return "ä»Šæ—¥æ— æ˜æ˜¾æ–°é—»é©±åŠ¨äº‹ä»¶"
        
        positive_count = len([n for n in news_driven if n.get("impact") == "positive"])
        total_count = len(news_driven)
        
        if positive_count / total_count > 0.7:
            return f"ä»Šæ—¥{total_count}æ¡é‡è¦æ–°é—»ä¸­{positive_count}æ¡åæ­£é¢ï¼Œæ•´ä½“åˆ©å¥½å¸‚åœº"
        else:
            return f"ä»Šæ—¥æ–°é—»é¢æ­£è´Ÿé¢å¹¶å­˜ï¼Œå¸‚åœºå½±å“ä¸­æ€§"
    
    def _calculate_momentum_indicators(self, market_data: Dict) -> Dict:
        """è®¡ç®—åŠ¨é‡æŒ‡æ ‡"""
        return {
            "volume_momentum": "5æ—¥å‡é‡è¾ƒä¸Šæ—¥å¢åŠ 35%",
            "price_momentum": "ä¸»è¦æŒ‡æ•°RSIå¤„äº60-70åŒºé—´",
            "breadth_momentum": "æ¶¨è·Œå®¶æ•°æ¯”è¾ƒå‰ä¸€æ—¥æ”¹å–„"
        }
    
    def _calculate_vix_equivalent(self, analysis: Dict) -> float:
        """è®¡ç®—æ¨¡æ‹ŸVIXæŒ‡æ•°"""
        # åŸºäºæ¶¨è·Œåœå®¶æ•°ã€èµ„é‡‘æµå‘ç­‰è®¡ç®—æ³¢åŠ¨ç‡
        base_vix = 15  # åŸºç¡€æ³¢åŠ¨ç‡
        
        try:
            if "sentiment" in analysis and "limit_analysis" in analysis["sentiment"]:
                limit_up = analysis["sentiment"]["limit_analysis"].get("limit_up", 0)
                limit_down = analysis["sentiment"]["limit_analysis"].get("limit_down", 0)
                
                # æ¶¨è·Œåœå®¶æ•°è¶Šå¤šï¼Œæ³¢åŠ¨ç‡è¶Šé«˜
                volatility_adjustment = (limit_up + limit_down * 2) * 0.5
                base_vix += volatility_adjustment
            
            return min(50, max(5, base_vix))
        except:
            return 15
    
    def _assess_rotation_strength(self, rotation_data: Dict) -> float:
        """è¯„ä¼°è½®åŠ¨å¼ºåº¦"""
        if not rotation_data or "leading_sectors" not in rotation_data:
            return 50
        
        leading = rotation_data["leading_sectors"]
        if leading and len(leading) > 0:
            top_change = leading[0].get("pct_chg", 0)
            return min(100, max(0, 50 + top_change * 5))
        return 50
    
    def _calculate_news_sentiment_score(self, news_data: Dict) -> float:
        """è®¡ç®—æ–°é—»æƒ…ç»ªè¯„åˆ†"""
        # ç®€åŒ–çš„æ–°é—»æƒ…ç»ªè¯„åˆ†
        if "important_announcements" in news_data:
            positive = news_data["important_announcements"].get("positive_count", 0)
            negative = news_data["important_announcements"].get("negative_count", 0)
            total = positive + negative
            if total > 0:
                return 50 + (positive - negative) / total * 50
        return 50
    
    def _get_fear_greed_level(self, score: float) -> str:
        """è·å–ææ…Œè´ªå©ªç­‰çº§"""
        if score >= 75:
            return "æåº¦è´ªå©ª"
        elif score >= 55:
            return "è´ªå©ª"
        elif score >= 45:
            return "ä¸­æ€§"
        elif score >= 25:
            return "ææ…Œ"
        else:
            return "æåº¦ææ…Œ"
    
    def _interpret_fear_greed_index(self, score: float) -> str:
        """è§£è¯»ææ…Œè´ªå©ªæŒ‡æ•°"""
        if score >= 75:
            return f"ææ…Œè´ªå©ªæŒ‡æ•°è¾¾{score}ï¼Œå¸‚åœºæƒ…ç»ªæåº¦ä¹è§‚ï¼Œæ³¨æ„é«˜ä¼°å€¼é£é™©"
        elif score >= 55:
            return f"ææ…Œè´ªå©ªæŒ‡æ•°ä¸º{score}ï¼Œå¸‚åœºè´ªå©ªæƒ…ç»ªè¾ƒæµ“ï¼Œé€‚åº¦è°¨æ…"
        elif score >= 45:
            return f"ææ…Œè´ªå©ªæŒ‡æ•°ä¸º{score}ï¼Œå¸‚åœºæƒ…ç»ªç›¸å¯¹å‡è¡¡ï¼Œå¯é€‚åº¦å‚ä¸"
        elif score >= 25:
            return f"ææ…Œè´ªå©ªæŒ‡æ•°ä¸º{score}ï¼Œå¸‚åœºææ…Œæƒ…ç»ªå‡æ¸©ï¼Œéœ€è°¨æ…æ“ä½œ"
        else:
            return f"ææ…Œè´ªå©ªæŒ‡æ•°ä»…{score}ï¼Œå¸‚åœºææ…Œæƒ…ç»ªæåº¦æµ“é‡ï¼Œå»ºè®®è§‚æœ›"
    
    def _build_analysis_prompt_data(self, analysis: Dict[str, Any]) -> Dict:
        """æ„å»ºç”¨äºLLMåˆ†æçš„æ•°æ®"""
        prompt_data = {
            "analysis_time": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "market_score": analysis.get("summary", {}).get("overall_score", 5.0),
            "fear_greed_score": analysis.get("fear_greed_index", {}).get("score", 50),
        }
        
        # å¸‚åœºæƒ…ç»ªæ•°æ®
        if "sentiment" in analysis:
            sentiment = analysis["sentiment"]
            prompt_data["sentiment"] = {
                "up_ratio": sentiment.get("up_down_ratio", {}).get("up_ratio", 0),
                "limit_up": sentiment.get("limit_analysis", {}).get("limit_up", 0),
                "emotion_score": sentiment.get("emotion_score", 5)
            }
        
        # èµ„é‡‘æµå‘æ•°æ®  
        if "capital" in analysis:
            capital = analysis["capital"]
            prompt_data["capital"] = {
                "north_funds": capital.get("north_funds", {}).get("total_net_inflow", 0),
                "main_funds": capital.get("main_funds", {}).get("net_inflow", 0)
            }
        
        # æ¿å—è½®åŠ¨æ•°æ®
        if "structure" in analysis and "sector_rotation" in analysis["structure"]:
            sectors = analysis["structure"]["sector_rotation"].get("leading_sectors", [])
            if sectors:
                prompt_data["hot_sectors"] = [{
                    "name": sector.get("name", ""),
                    "change": sector.get("pct_chg", 0)
                } for sector in sectors[:3]]
        
        # é¢„è­¦ä¿¡æ¯
        if "alerts" in analysis:
            high_alerts = [alert for alert in analysis["alerts"] if alert.get("level") == "high"]
            if high_alerts:
                prompt_data["major_alerts"] = [alert["message"] for alert in high_alerts[:3]]
        
        return prompt_data
    
    def _call_llm_for_analysis(self, prompt_data: Dict) -> str:
        """è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½åˆ†æ"""
        try:
            import requests
            
            # æ„å»ºç®€åŒ–çš„åˆ†ææç¤ºè¯
            market_score = prompt_data.get('market_score', 5)
            fear_greed = prompt_data.get('fear_greed_score', 50)
            
            # æ ¹æ®æ•°æ®åˆ¤æ–­å¸‚åœºçŠ¶æ€
            if market_score >= 7:
                trend = "å‘å¥½"
            elif market_score >= 4:
                trend = "éœ‡è¡"
            else:
                trend = "åå¼±"
                
            if fear_greed >= 70:
                emotion = "è´ªå©ª"
            elif fear_greed >= 30:
                emotion = "ä¸­æ€§"
            else:
                emotion = "ææ…Œ"
            
            system_prompt = f"å½“å‰å¸‚åœº{trend}ï¼Œæƒ…ç»ª{emotion}ã€‚åŸºäºå¸‚åœºè¯„åˆ†{market_score}/10å’Œææ…Œè´ªå©ªæŒ‡æ•°{fear_greed}/100ï¼Œç»™å‡º100å­—ä»¥å†…çš„å¸‚åœºè§£è¯»å’Œæ“ä½œå»ºè®®ã€‚ç›´æ¥è¾“å‡ºç»“è®ºï¼Œä¸è¦æœ‰æ€è€ƒè¿‡ç¨‹ã€‚"
            
            # ç®€åŒ–æ•°æ®è¾“å…¥
            user_prompt = "è¯·åˆ†æã€‚"
            
            body = {
                "model": OLLAMA_MODEL,
                "prompt": system_prompt + "\n" + user_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_ctx": 512,
                    "num_predict": 150,
                    "stop": None
                }
            }
            
            response = requests.post(f"{OLLAMA_URL}/api/generate", json=body, timeout=10)
            response.raise_for_status()
            
            result = response.json().get("response", "").strip()
            # å»é™¤thinkingæ ‡ç­¾å’Œå…¶ä»–æ€è€ƒå†…å®¹
            if "<think>" in result:
                # æ‰¾åˆ°</think>æ ‡ç­¾çš„ä½ç½®
                think_end = result.find("</think>")
                if think_end != -1:
                    result = result[think_end + 8:].strip()
            
            # å¦‚æœåŒ…å«"thinking"ç­‰å…³é”®è¯ï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ
            if "thinking" in result.lower() or "ç”¨æˆ·" in result or not result:
                return self._get_fallback_narrative(prompt_data)
            
            return result
            
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._get_fallback_narrative(prompt_data)
    
    def _format_prompt_for_llm(self, prompt_data: Dict) -> str:
        """æ ¼å¼åŒ–LLMæç¤ºè¯"""
        prompt = f"ã€å¸‚åœºæ•°æ®æ‘˜è¦ã€‘\n"
        prompt += f"åˆ†ææ—¶é—´ï¼š{prompt_data.get('analysis_time', '')}"
        prompt += f"å¸‚åœºè¯„åˆ†ï¼š{prompt_data.get('market_score', 5.0)}/10\n"
        prompt += f"ææ…Œè´ªå©ªæŒ‡æ•°ï¼š{prompt_data.get('fear_greed_score', 50)}/100\n\n"
        
        if "sentiment" in prompt_data:
            s = prompt_data["sentiment"]
            prompt += f"ã€æƒ…ç»ªæŒ‡æ ‡ã€‘æ¶¨è·Œæ¯”{s.get('up_ratio', 0)}%ï¼Œæ¶¨åœ{s.get('limit_up', 0)}å®¶\n"
        
        if "capital" in prompt_data:
            c = prompt_data["capital"]
            prompt += f"ã€èµ„é‡‘æµå‘ã€‘åŒ—å‘èµ„é‡‘{c.get('north_funds', 0):.1f}äº¿ï¼Œä¸»åŠ›èµ„é‡‘{c.get('main_funds', 0):.1f}äº¿\n"
        
        if "hot_sectors" in prompt_data:
            sectors = prompt_data["hot_sectors"]
            sector_text = "ã€".join([f"{s['name']}({s['change']:.1f}%)" for s in sectors[:3]])
            prompt += f"ã€çƒ­ç‚¹æ¿å—ã€‘{sector_text}\n"
        
        if "major_alerts" in prompt_data:
            alerts = prompt_data["major_alerts"]
            prompt += f"ã€é‡è¦é¢„è­¦ã€‘{'; '.join(alerts[:2])}\n"
        
        prompt += "\nè¯·åŸºäºä»¥ä¸Šæ•°æ®ç”Ÿæˆä¸“ä¸šå¸‚åœºåˆ†æï¼š"
        
        return prompt
    
    def _get_fallback_narrative(self, analysis_or_data) -> str:
        """è·å–åå¤‡è§£è¯»å™è¿°"""
        try:
            # æå–å¸‚åœºè¯„åˆ†å’Œææ…Œè´ªå©ªæŒ‡æ•°
            if isinstance(analysis_or_data, dict) and "market_score" in analysis_or_data:
                # è¿™æ˜¯ prompt_data
                score = analysis_or_data.get("market_score", 5.0)
                fear_greed = analysis_or_data.get("fear_greed_score", 50)
            else:
                # è¿™æ˜¯ analysis åŸå§‹æ•°æ®
                score = analysis_or_data.get("summary", {}).get("overall_score", 5.0)
                fear_greed = 50  # é»˜è®¤å€¼
            
            # æ ¹æ®è¯„åˆ†å’Œæƒ…ç»ªç”Ÿæˆæ™ºèƒ½è§£è¯»
            if score >= 7 and fear_greed < 70:
                return (
                    "ã€æ ¸å¿ƒé€»è¾‘ã€‘å¸‚åœºè¶‹åŠ¿å¼ºåŠ¿ï¼Œèµ„é‡‘æ´»è·ƒåº¦é«˜ï¼Œçƒ­ç‚¹æ¿å—è½®åŠ¨æœ‰åºã€‚\n"
                    "ã€æ“ä½œç­–ç•¥ã€‘å»ºè®®ä»“ä½60-70%ï¼Œå…³æ³¨å¼ºåŠ¿æ¿å—é¾™å¤´ï¼Œè®¾ç½®8%æ­¢æŸã€‚\n"
                    "ã€é£é™©æç¤ºã€‘é˜²èŒƒçŸ­æœŸå›è°ƒï¼Œåˆ†æ‰¹å»ºä»“é™ä½æˆæœ¬ã€‚"
                )
            elif score >= 7 and fear_greed >= 70:
                return (
                    "ã€æ ¸å¿ƒé€»è¾‘ã€‘å¸‚åœºè™½å¼ºä½†æƒ…ç»ªè¿‡çƒ­ï¼Œæœ‰é«˜ä½éœ‡è¡é£é™©ã€‚\n"
                    "ã€æ“ä½œç­–ç•¥ã€‘é€æ­¥å‡ä»“è‡³40-50%ï¼Œé”å®šåˆ©æ¶¦ï¼Œç­‰å¾…å›è°ƒæœºä¼šã€‚\n"
                    "ã€é£é™©æç¤ºã€‘å¸‚åœºè´ªå©ªæƒ…ç»ªæµ“åšï¼Œè­¦æƒ•å¿«é€Ÿè°ƒæ•´ã€‚"
                )
            elif score >= 4:
                return (
                    "ã€æ ¸å¿ƒé€»è¾‘ã€‘å¸‚åœºéœ‡è¡æ•´ç†ï¼Œå¤šç©ºåšå¼ˆæ¿€çƒˆï¼Œç»“æ„æ€§è¡Œæƒ…ä¸ºä¸»ã€‚\n"
                    "ã€æ“ä½œç­–ç•¥ã€‘ç»´æŒä»“ä½40-50%ï¼Œé«˜æŠ›ä½å¸ï¼Œå…³æ³¨è¶…è·Œåå¼¹ã€‚\n"
                    "ã€é£é™©æç¤ºã€‘æ§åˆ¶å•ä¸€æŒä»“ï¼Œè®¾ç½®ä¸¥æ ¼æ­¢æŸã€‚"
                )
            else:
                return (
                    "ğŸš¨ ã€æ ¸å¿ƒé€»è¾‘ã€‘å¸‚åœºæƒ…ç»ªåå¼±ï¼Œèµ„é‡‘è°¨æ…ï¼Œçƒ­ç‚¹ç¼ºä¹æŒç»­æ€§ã€‚\n"
                    "ğŸ’° ã€æ“ä½œç­–ç•¥ã€‘é™ä½ä»“ä½è‡³30%ä»¥ä¸‹ï¼Œä¿æŒå……è¶³ç°é‡‘ã€‚\n"
                    "âš™ï¸ ã€é£é™©æç¤ºã€‘å¸‚åœºä»åœ¨å¯»åº•ï¼Œè°¨æ…æŠ„åº•ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·ã€‚"
                )
        except:
            return (
                "ğŸ¤– ã€AIåˆ†æã€‘æ•°æ®è·å–ä¸­ï¼Œè¯·ç¨åæŸ¥çœ‹åˆ†æç»“æœã€‚\n"
                "ğŸ“Š ã€æ“ä½œå»ºè®®ã€‘ä¿æŒè°¨æ…ï¼Œç­‰å¾…æ˜ç¡®ä¿¡å·ã€‚\n"
                "âš ï¸ ã€é£é™©æç¤ºã€‘åˆ†ææ•°æ®ä¸å®Œæ•´ï¼Œè¯·ç»“åˆå…¶ä»–ä¿¡æ¯åˆ¤æ–­ã€‚"
            )


# å•ä¾‹æ¨¡å¼
_market_ai_analyzer = None

# å¢å¼ºç‰ˆMarketAIAnalyzer
class EnhancedMarketAIAnalyzer(MarketAIAnalyzer):
    """å¢å¼ºç‰ˆå¸‚åœºAIåˆ†æå™¨ï¼Œé›†æˆLLMæ™ºèƒ½åˆ†æ"""
    
    def __init__(self):
        super().__init__()
        self.llm_enabled = True
        
    def generate_market_insight_report(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„å¸‚åœºæ´å¯ŸæŠ¥å‘Š"""
        try:
            # åŸºç¡€åˆ†æ
            analysis = self.analyze_comprehensive_market(market_data)
            
            # æ·»åŠ é«˜çº§ç‰¹æ€§
            analysis["advanced_features"] = {
                "ai_powered": True,
                "llm_model": OLLAMA_MODEL,
                "analysis_version": "v2.0_enhanced",
                "features": [
                    "æ™ºèƒ½åŒ–è§£è¯»å™è¿°",
                    "ææ…Œè´ªå©ªæŒ‡æ•°",
                    "å®æ—¶çƒ­ç‚¹è¿½è¸ª",
                    "æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ"
                ]
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"å¸‚åœºæ´å¯ŸæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_analysis()


def get_market_ai_analyzer() -> EnhancedMarketAIAnalyzer:
    """è·å–å¢å¼ºç‰ˆå¸‚åœºAIåˆ†æå™¨å®ä¾‹"""
    global _market_ai_analyzer
    if _market_ai_analyzer is None:
        _market_ai_analyzer = EnhancedMarketAIAnalyzer()
    return _market_ai_analyzer

# ä¿æŒå‘åå…¼å®¹
def get_enhanced_market_ai_analyzer() -> EnhancedMarketAIAnalyzer:
    """è·å–å¢å¼ºç‰ˆå¸‚åœºAIåˆ†æå™¨å®ä¾‹ï¼ˆæ–°æ¥å£ï¼‰"""
    return get_market_ai_analyzer()